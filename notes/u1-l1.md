# Unit 1: Python Basics

# Lecture 1: Introduction To Python

## Intro

---
### When Given A New Challenge, How Can I Get The Computer To Solve It For Me?
---

> How can I describe the stages I want to use to get this done in such a manner that I don't have to do it?  

This is the notion of computational thinking -- algorithmic thinking -- and that's the focal point of the course


> If we want the computer to compute something for us, infer some new knowledge for us, we'll have to think about how we are going to represent that knowledge.  
> We do this with particular things inside the machine called data structures.  

We want it to infer new information or define information, and we're going to see that there are standard tools for making that happen.  
- iteration
- recursion

Also a big part of what we want to do inside the computer is to have it be able to deal with things in a manner that we can see and understand.  

We're going to use the notion of abstraction to capture elements and treat them as if they were primitives and reuse them.  
- this naturally leads to the idea of modularization:
    - creating *modules*, *tokens*, and *elements* that we can stitch together to come up with solutions to problems in interesting ways
    - organizing/modularizing systems using objects and classes and methods
(abstraction of *procedures* and *data types*)

Once we start learning how to build algorithms to think algorithmically, we're going to see that there are **standard classes** of algorithms, and we're going to use those for common problems like **searching** and **sorting**.  
We're going to see as well that different algorithms have different costs:
- we want to see how to use that to reason about the expense of doing something a particular way and better ways of finding a solution to different problems

---
### Fundamentally, A Computer Only Really Does Two Things:  
---

- performs calculations
    - somewhere in the order of a billion per second (two operations in the time it takes for light to travel one foot)
- remembers things
    - hundreds of gigabytes of storage per device (about 1.5 million books of standard length)

It performs calculations (duh), but in this case, the calculations are actually very simple things.  
Also turns out that computers can do these calculations amazingly fast, but they still **only** perform calculations.  

Early computers didn't have much power in the way of remembering things, and now modern computers have a **lot**.  

Still, that's it at the core:
> 1. *perform calculations*  
> 2. *remember results*

---
### What Kinds Of Calculations Can Computers Do Then?  
---

- the kinds built-in to the language
    - every computer comes with a set of built-in operations
            - these are typically primitive arithmetic operations -- multiplication, addition, division -- and simple logic operations (comparing true and false values)

If that were all we had, it'd be a pain; in this course we'll figure out how to define new calculations, new operations, things we can create and give to the computer so that it can abstract them, encapsulate them, and treat them as if they were primitives.
- i.e., ones that **you define** as the programmer

So, simple primitive calculations very quickly.  Is that enough?  It might be.  If that's the case, we really don't have much to do in terms of computation, but it's not.
Even with the speed of modern computers, you need to be able to think carefully, cleverly, algorithmically.  

---
### Simple Calculations Enough?  Storage Enough?
---

Searching the World-Wide Web
- 45 billion pages; 100 words per page; 10 operations/word to find
- need 5.2 days to find something using simple operations

Playing chess
- average chess of 35 moves/setting; look ahead 6 moves; 1.8 billion boards to check; 100 operations/choice
- 30 minutes to decide each

Good algorithm design is also required to a accomplish a task, as you can see!  You *can't* just use brute force or pre-compute.

And if you ask why we can't simply pre-compute and then look up answers:
- playing chess, for example, experts suggest 10^123 different possible games could exist
    - there are only about 10^80 atoms in the observable universe, to put this into context

So, despite its speed and storage capabilities, a computer definitely has limitations:
- some problems are still too complex to solve in a reasonable timespan:
    - accurate weather predictions at a local scale
    - cracking encryption schemes
- some problems are fundamentally impossible to compute:
    - Turing halting problem: predicting whether a piece of code will always halt with an answer for any input is impossible

Even with that, we're going to ask are there going to be limits to computation, even if I can build clever algorithms?

---
---

## 1.1 Knowledge

What do we want a computer to do for us?  We want it to compute something, of course.  
If we want it to compute something, well what's the knowledge that it's going to use to do that computation?  

This leads to an interesting distinction, because we can divide knowledge into two types:
- declarative knowledge
- imperative knowledge

---
### Types Of Knowledge
---

declarative knowledge
: statement of facts (ex., there is candy taped to the underside of a chair)

doesn't tell you where to look for it; you would have to either do it in parallel by having everyone reach under their own seat at once, or searching the whole lecture hall individually  
- simply a statement of fact


vs.

imperative knowledge
: recipe or "how-to" knowledge (ex., face a certain side of room, count up three rows, start from middle section's left side, count 1 chair to the right, reach under chair and find candy)

- sequence of steps to find a solution or get things done, very mechanical

---
### Numerical Example
---

Suppose I want to compute the square root of some integer; here's a statement of fact -- the square root of the number `x` is `y` such that `y*y` is equal to `x`.  

Does this tell us how to find a square root?  No.  If someone gives me a good guess, I can use this knowledge to check.  But it doesn't help me find something.

Here's a very old version of imperative knowledge that's attributed to Heron of Alexandria in the 2nd century B.C. (although it's suggested to have predated that, even) for finding a square root
> start with a guess, called `g`, and if `g*g` is close enough to `x`, then I can stop and say `g` is the answer.  Otherwise, I'm going to create a new guess by taking `g` and `x/g` and averaging the two together.  
> Ok, once you've done that, repeat the process.

That gives us a little algorithm!  I.e., start with a guess, and check to see if the guess is close enough, and if not, keep going.

| `g` | `g*g` | `x/g` | `(g+x/g)/2` |
| --- | --- | --- | --- |
| 3 | 9 | 5.333 | 4.1667 |
| 4.1667 | 17.36 | 3.837 | 4.0035 |
| 4.0035 | 16.0277 | 3.997 | 4.000002 |

You can see in the above table how the algorithm converges on the square root of 16, which is 4.

---
### What Is A Recipe?
---

Three pieces of an algorithm:
1. sequence of simple steps
2. flow control process
    - a process that specifies when each step is executed
3. means of determining when to stop

---
---

## 1.2 Machines

Computers are machines.
How do I capture a recipe inside a mechanical process?

For example, say we wanted to get a machine to compute square roots for me:  
Historically, there were two choices here:
- fixed program - machine designed to calculate a particular computation
    - calculator
    - Turing's Bombe (made out of vaccum tube and relays, this machine decrypted German communications that were encrypted using the Enigma machine)
- stored program
    - machine stores and executes instructions
    - can load into it that description, that sequence of instructions, that recipe
        - then inside the machine, there are going to be a set of parts that are going to do those instructions when I ask them to
        - in particular, there's a special program called the interpreter that's going to walk through each in those sequence of instructions, in turn, doing the computation that I want

The advantage of a stored program computer is that I can load in a different program and have it do the same thing.  In essence, that stored program computer is emulating or imitating a fixed program computer for each program that I load in.  This gives us an infinite range of things to be able to do.  

With that in mind, what I want to think about is, how do I take a description of a process in those mechanical steps and write it in such a way that I can load it into the computer and can do the work for me?

Before I do that, I need to think about what's inside the machine...

---
### Basic Machine Architecture
---

Basic machine architecture of a computer has some simple pieces
- Memory -- places in which I'm going to store things
    - up here could be data, but it could also be a sequence of instructions that are my program, that mechanical set of steps
- Input/Output -- a way to load things into the machine and print things out of the machine
- the "heart of the machine" consists of two elements:
    - ALU: Arithmetic Logic Unit
        - takes info from memory, reads it in -- often two pieces of info if I'm going to do an operation that takes two inputs -- to do primitive operation(s) and subsequently, typically store stuff back up into memory
        - to make that happen, we need one or more piece(s):
    - Control Unit
        - keeps track of what a specific operation I want to do in that ALU at each point in time
        - inside the control unit is an important thing called a program counter
            - when I load a program into the machine (the sequence of instructions in memory) the program counter points to the location of the first instruction
            - when I ask the machine to execute, the program counter reads that first instruction, causes an operation to take place, and then is going to add one to the program counter, which is going to take it to the next instruction in the sequence to do another operation, move things back into memory, and increase the program counter
            - eventually, we're going to get to a test that says whether something is true or false
                - based on that, we're going to change the program counter to go back up, for example, to the beginning of the code

This is, in essence, what happens inside a modern machine.  
Our goal now is to figure out how to write the sequence of instructions so that the computer can do the things I want it to

---
### To Summarize,
---

> a stored program is going to be that sequence of instructions, built out of simple arithmetic and logic operations, simple tests, going to allow us to move data around  

> associated with that is going to be this special program called the interpreter that's going to execute each of those sequences of instructions in order, changing things with the flow of control when a test says, "I want to go somewhere else"

> finally, when I'm done, print out the answer

---
### Basic Primitives
---

Most machines come with simple arithmetic and logic operations, but, in fact, you can go even deeper than that...  
Turing showed that you can compute anything with just six primitives
- Turing machine
    - infinite tape with a set of squares on it; in each, there's a symbol that could be 1 or 0
        - if you have six operations (move left, move right, scan, print, erase, do nothing)
    - with just those primitives, you can compute anything that's computable

Modern programming languages, luckily, come with a more convenient set of primitives.  
The fundamental idea, still, is that you can compute anything with just a simple set

You don't want to just write everything in terms of addition, subtraction, logical tests.  Rather, you want to write descriptions and abstract them.  I.e., abstract methods to create new  

Abstraction
: treat that operation that I created like the square root function as if the manufacturer had built a little primitive and installed it on your machine; you want to be able to use it as if it was something that came with the machine, and that's what the power of computational thinking is going to give us.

Anything computable in one language is computable in any other programming language. Having this property means a language is Turing complete (one of the fundamentals of computer science).   

In some languages, it's going to be easier to do some kinds of things versus others:
- in MATLAB, it's easy to manipulate matrices
- in PHP, it's easy to deal with web programming

---
---

## 1.3 Languages

Knowing that we want to create a generic recipe and knowing a bit about what's inside the machine, we want to now go from a description of a process to a specific set of statements that we can store in the machine so that the interpreter, that evaluator, can then run those operations to use the primitives inside the machine to do the work for us.  

---
### Creating Recipes
---

As we said, the programming lanuguage is going to come with a set of primitve operations, and the next step is to think about how we put them together.  
To do that, we use something that we call an **expression**.

*Expressions*
: more complex but legal combinations of primitives that the programming language will recognize

Any legal expression in a programming language, any computation, has associated with it a value.  That *value* is the *meaning* of the expression.  That's going to be important, in part because if we know what we want to get from a particular computation, we want to understand how we get to that value; how we back-out of that sequence of steps the expressions that are going to compute it for us.

---
### Aspects Of Languages
---

Every programming language can be thought of as:
1. consisting of a set of primitives
2. means of combination (way of putting those primitives together to create new expressions)
3. means of abstraction (way of taking some complex expression and treating it as if it were a primitive)

In English, what are the primitive constructs?  They're words; lots of them, some more common than others.  
In a programming language, they're the atoms on which we're going to build things.
- in a programming language, they're typically numbers, strings, or just sequences of characters, and simple, built-in operations (addition, multiplication, division)

When we put primitives together, we have to think about two different parts:
1. syntax
2. semantics

Syntax
: parsing of a sentence to know if this is a legal sentence or not (and some combinations of expressions are legal while others are not)
- In English:  
"cat dog boy" doesn't mean anything and isn't syntactically valid (no verb)  
"cat hugs boy" is syntactically valid
- In programming languages:  
"hi5" not syntactically valid  
3.2*5 is syntactically valid

*Static semantics*
: tells us which syntactically valid strings have meaning
- In English:  
"I are hungry" is syntactically valid, but has a static semantic error
- In programming languages:  
3+"hi" is a static semantic error

So we have to distinguish things that are not statically semantically valid because they're not going to be the expressions to which we want to try to assign meaning.  

*Semantics*
: the meaning associated with a syntactically correct string of symbols with no static semantic errors
- In English, can have many meanings.  
- In programming languages, have only one meaning but may not be what the programmer intended (this is where bugs can arise)

---
### Where Things Can Go Wrong
---

- **syntactic errors**
    - common and easily caught
- **static semantic errors**
    - some languages check for these before running program
    - can cause unpredictable behavior
- no semantic errors but **different meaning than what the programmer intended**
    - program crashes, stops running
    - program runs forever
    - program gives an answer, but different from expected results

---
### Our Goal
---

- Learn the syntax and semantics of a programming language
- Learn how to use those elements to translate "recipes" for solving a problem into a form that the computer can use to do the work for us
- Learn computational modes of thinking to enable us to leverage a suite of methods to solve complex problems
    - different style of solving problems, as those styles are going to be common and can easily be reused when we see a new problem that fits into the same category

---
### Recap
---

Syntax
: determings whether a string is legal

Static semantics
: determines whether a string has meaning

Semantics
: assigns a meaning to a legal sentence

---
---

## 1.4 Types

Now that we have an idea that we want to put together expressions by combining primitives in legal ways, we can start capturing algorithms

---
### Python Programs
---

- a **program** is a sequence of definitions and commands
    - definitions *evaluated*
        - ways of either assigning names to values or creating procedures to be treated as primitives
    - commands *executed* by Python interpreter in a shell
- commands (are statements that) instruct the interpreter to do something
    - simpler expressions that we can execute directly within Python using a shell
- can be typed directly into a sheell or stored in a file that is read to the shell and evaluated

Shell
: simply a window into which I can type expressions and the interpreter is listening for them
- they get passed into the interpreter, it follows the set of instructions to figure out what the semantics are, the meaning associated with that expression
- subsequently prints out the result

Commands
: could be, simply, do this arithmetic operation; or it could be apply a primitive that I created to do some work for me

---
### Objects
---

- programs manipulate **data objects**
    - ... in order to get out parts of those objects or to do something with those objects
- objects have a **type** that defines the kinds of things programs can do to them
    - i.e. the type tells programs whether they can act on it or not in a given context (if program expecting number gets string, it's not going to try to do anything with that)
- objects are either:
    - scalar (cannot be subdivided)
        - `int` represents **integers** (ex. `5`)
        - `float` represents **real numbers** (ex. `3.14159`)
        - `bool` represents **Boolean** values (`True` and `False`), which are very important for tests
        - `NoneType` is a **special** type that has **one value** (`None`)
        - can use `type()` to see the type of an object (`type(5)` evaluates to `int` in shell)
    - non-scalar (have internal structure that can be accessed)

---
### Type Conversions (Cast)
---

- can convert object of one type to another
    - `float(3)` converts integer `3` to float `3.0`
    - `int(3.14159)` truncates down to the integer `3`

Knowing these types, we can start putting things together.  

---
### Printing To Console
---

Here's a legal expression:  
`3+2`  
That has a value associated with it.  In fact, the expression is to take the 3 and the 2 and apply the arithmetic operation of addition to them.  
When I evaluate it, it simply *returns* out 5.  

Makes sense.  
Sometimes, however, you might want to use something that will print.  
Typing `print`, which controls output to the console (in this case, saying, "print 3 plus 2"), is a little different in that *no value is **returned***.  
- `print` returns `NoneType`, to be precise

Why this difference?  What we're going to see is, when we're in the middle of a computation and we want to print something out to the shell, we can use a `print` command to do that.  If we were to instead return the value, that goes back into the computation to be used for the next step.  

> I.e., in the simple *first* case, the whole value of the computation was 3 plus 2 equals 5.  
> In the *second* case, the *side effect* is to print something while the *value returned* is nothing.

---
### Expressions
---

To combine objects and operators into expressions, we use a standard form.  The syntax is simply and object, an operator, and another object.  
`<object><operator><object>`  
*Any* expression like this that is syntactically valid has a **value**, which itself is a **type**.  

---
### Operators On `int`s And `float`s
---

> |  |  |  |
> | --- | --- | --- |
> | `i+j` | the **sum** | if `i` and `j` are `int`s, result is `int`, if *either* or *both* are `float`s, the result is `float` |
> | `i-j` | the **difference** | ^ |
> | `i*j` | the **product** | ^ |
> | `i/j` | **division** | result is `float` |
> | `i//j` | **int division** | result is `int`, quotient *without* remainder |
> | `i%j` | the **remainder** when `i` divided by `j` |  |
> | `i**j` | `i` to the **power** of `j` |  |

---
### Simple Operations
---

Parentheses are used to tell Python the order of operations (innermost parentheses being evaluated first)
- `3*5+1` evaluates to `16`
- `3*(5+1)` evaluates to `18`  

Operator precedence without parentheses:
- `**`
- `*`
- `/`
- `+` and `-` executed left to right as they appear in the expression

---

## 1.5 Variables

*Abstraction* in one form
: giving things names so that we can refer to a value by that name and reuse it as needed.  
This is the first form of abstraction that we'll see.

---
### Binding Variables And Values
---

- the **equal** sign is an **assignment** of a variable to a name
    - ex. `pi = 3.14159`
    - ex. `pi_approx = 22/7`
- value stored in computer memory
- as assignment binds name to value
- retrieve value associated with name or variable by invoking the name by typing `pi`

---
### Abstracting Expressions
---

Why give names to expressions?
- want to reuse the name and not have to redo the computation to get the value
- gives me code that's much easier to understand because these names ought to be informative
    - lets me think about what it's telling me about what it represents
- easier to change the code later if I've just got a name and I want to change the binding of the name and reuse it
```python
pi = 3.14159  
radius = 2.2  
area = pi*(radius**2)  
```

---
### Changing Bindings
---

- can **re-bind** variable names using a new assignment statement
- previous value may still be stored in memory but lost the handle for it
- value for area does not change until you tell the computer to do the calculation again
```python
pi = 3.14
radius = 2.2
area = pi*(radius**2)
radius += 1
```


---

## 1.6 Operators And Branching

So far, we've explored arithmetic operations, but the next piece we'll add in is the ability to make decisions based on **tests**.  
For that, we have to compare things.  

Am I close enough to the square root that I'm done (with Heron of Alexandria's algorithm)?  Am I close enough to something else in another algorithm's implementation?  

---
### Comparison Operators On `int` And `float`
---

- `i` and `j` are any variable names:
    - `i>j`
    - `i>=j`
    - `i<j`
    - `i<=j`
    - `i==j` is an equality test, `True` if `i` equal to `j`
    - `i!=j` is an **inequality** test, `True` if `i` *not* equal to `j` (bang equal)

---
### Logic Operators On `bool`s
---

- `a` and `b` are any variable names
    - `not a`
        - evaluates to `True` if `a` is `False`
        - evaluates to `False` if `a` is `True`
    - `a and b`
        - `True` if both are `True`
    - `a or b`
        - `True` if either or both are `True`

---
### Branching Program
---

- the simplest branching statement is a **conditional**  
    - a test (expression that evaluates to `True` or `False`)
    - a block of code to execute if the test is `True`
    - an optional block of code to execute if the test is `False`

In Python, we don't necessarily need to have the `False` block, but we have to have the `True` block (if "this" is true, there should be something to do).  
I.e., if it's not always the case that I want to do something even when it's not true, I can skip that.

---
### Simple Example
---

```python
x = int(input('Enter an integer: '))
if x%2 == 0:
    print('')
    print('Even')
else:
    print('')
    print('Odd')
print('Done with conditional')
```

This example has a `True` block and a `False` block.  
The **indentation** delineates the blocks.  

---
### Nested Conditionals
---

```python
if x%2 ==0:
    if x%3 == 0:
        print('Divisible by 2 and 3')
    else:
        print('Divisible by 2 and not by 3')
elif x%3 == 0:
    print('Divisible by 3 and not by 2')
```

---
### Compound Booleans
---

```python
if x < y and x < z:
    print('x is the least')
elif y < z:
    print('y is the least')
else:
    print('z is the least')
```

---
### Control Flow - Branching
---
```python
if <condition>:
    <expression>
    <expression>
    ...
```

```python
if <condition>:
    <expression>
    <expression>
    ...
else:
    <expression>
    <expression>
    ...
```

```python
if <condition>:
    <expression>
    <expression>
    ...
elif <condition>:
    <expression>
    <expression>
    ...
else:
    <expression>
    <expression>
    <expression>
    ...
```

- `<condition>` has a value `True` or `False`
- evaluate expressions in that block if `<condition>` is `True` 

---
### What Have We Added?
---

- branching programs allow us to make choices and do different things
- still the case that, at most, each statement gets executed once
- so the maximum time to run a program depends only on the length of the program
- these programs are *linear* and run in ***constant time***

---